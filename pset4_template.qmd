---
title: "Your Title"
format: 
  pdf:
    keep-tex: true
    include-in-header: 
       text: |
         \usepackage{fvextra}
         \DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaklines,commandchars=\\\{\}}
include-before-body:
  text: |
    \RecustomVerbatimEnvironment{verbatim}{Verbatim}{
      showspaces = false,
      showtabs = false,
      breaksymbolleft={},
      breaklines
    }
---

**PS4:** Due Sat Nov 2 at 5:00PM Central. Worth 100 points. 

## Style Points (10 pts)

## Submission Steps (10 pts)

## Download and explore the Provider of Services (POS) file (10 pts)

1. 



2. 
    a.
    
    ```{python}
    import pandas as pd
    import numpy as np

    # Read the file firstly
    df_2016 = pd.read_csv("D:/uchicago/24 fall/data/ps4/POS_File_Hospital_Non_Hospital_Facilities_Q4_2016.csv", low_memory = False)
    df_2016.head()

    # Count the number of short-term hospitals
    short_term_hos_2016 = df_2016[(df_2016['PRVDR_CTGRY_SBTYP_CD'] == 1) & (df_2016['PRVDR_CTGRY_CD'] == 1)]
    print(len(short_term_hos_2016))
    ```

    From the result, we could see that the number of short-term hospitals from the dataset are 7245. This does not make sense.

    From the outer sources, we could see that, the total number of All U.S. Registered Hospitals are 5534, which is far lower than the result from dataset. (https://www.aha.org/system/files/2018-02/2018-aha-hospital-fast-facts.pdf)

    Morevoer, we cannot find the exact term of 'short-term' hospital, but we did find a similary term, which is community hospital, the data of community hospitals in 2016 is 3385+1882=5267 (https://www.ahadata.com/hospitaltrendwatch/hospitalorganizationaltrends), which is very close to the number for the total number of registered hospitals in U.S. While the definition of community hospital is community hospitals included all non-federal, short-term general and specialty hospitals whose facilities and services are available to the public. Therefore, since the community hospital has included the number of short-term general and specialty hospitals. The number from the dataset is not making any sense since it far more exceeds the number for the other resouces.



    b. From my perspective, the differences could be the following reasons:
    1. The discrepancy may be due to variations in how short-term is defined across datasets. POS may include more specialized facilities under the short-term designatio taht AHA excludes.
    2. The POS dataset might include affiliated or multilocation entries separately, whereas AHA may consolidate these under single institutional entries.
    3. The POS dataset might have wrong data entry progress, making the dataset includes duplicate hospitals.

3. 

```{python}
# Load the datasets
df_2017 = pd.read_csv('D:/uchicago/24 fall/data/ps4/POS_File_Hospital_Non_Hospital_Facilities_Q4_2017.csv', low_memory = False)
df_2018 = pd.read_csv('D:/uchicago/24 fall/data/ps4/POS_File_Hospital_Non_Hospital_Facilities_Q4_2018.csv', low_memory = False)
df_2019 = pd.read_csv('D:/uchicago/24 fall/data/ps4/POS_File_Hospital_Non_Hospital_Facilities_Q4_2019.csv', low_memory = False)

# Calculate the quantities for each year
short_term_hos_2017 = df_2017[(df_2017['PRVDR_CTGRY_SBTYP_CD'] == 1) & (df_2017['PRVDR_CTGRY_CD'] == 1)]
short_term_hos_2018 = df_2018[(df_2018['PRVDR_CTGRY_SBTYP_CD'] == 1) & (df_2018['PRVDR_CTGRY_CD'] == 1)]
short_term_hos_2019 = df_2019[(df_2019['PRVDR_CTGRY_SBTYP_CD'] == 1) & (df_2019['PRVDR_CTGRY_CD'] == 1)]

# Quantities
print(len(short_term_hos_2017))
print(len(short_term_hos_2018))
print(len(short_term_hos_2019))

# presetting
short_term_hos_2016_selected = short_term_hos_2016[['PRVDR_CTGRY_SBTYP_CD', 'PRVDR_CTGRY_CD']]
short_term_hos_2017_selected = short_term_hos_2016[['PRVDR_CTGRY_SBTYP_CD', 'PRVDR_CTGRY_CD']]
short_term_hos_2018_selected = short_term_hos_2016[['PRVDR_CTGRY_SBTYP_CD', 'PRVDR_CTGRY_CD']]
short_term_hos_2019_selected = short_term_hos_2016[['PRVDR_CTGRY_SBTYP_CD', 'PRVDR_CTGRY_CD']]
short_term_hos_2016_selected['Year'] = 2016
short_term_hos_2017_selected['Year'] = 2017
short_term_hos_2018_selected['Year'] = 2018
short_term_hos_2019_selected['Year'] = 2019

# Append them together
total_short = pd.concat([short_term_hos_2016_selected, short_term_hos_2017_selected, short_term_hos_2018_selected, short_term_hos_2019_selected], ignore_index = True)

# Plot the quantities over time
yearly_counts = total_short.groupby('Year').size()
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 8))
yearly_counts.plot(kind = 'bar', color = 'skyblue', edgecolor = 'black')
plt.title("Number of Short-Term Hospitals Reported Over Year")
plt.xlabel("Year")
plt.ylabel('Number of Hospital')
plt.grid(axis ='y', linestyle = '--', alpha = 0.7)
plt.show()


```

4. 
    a.
    
    ```{python}
    # Define the function to filter the unique hospital with valid CMS
    def filter_cms_hospitals(df):
      short_term = short_term[short_term['PRVDR_NUM'].astype(str).str.len().isin(6, 10)]
      return short_term

    # Filter apply
    df_2016_4 = filter_cms_hospitals(df_2016)
    df_2017_4 = filter_cms_hospitals(df_2017)
    df_2018_4 = filter_cms_hospitals(df_2018)
    df_2019_4 = filter_cms_hospitals(df_2019)
    
    # Add year column
    df_2016_4['Year'] = 2016
    df_2017_4['Year'] = 2017
    df_2018_4['Year'] = 2018
    df_2019_4['Year'] = 2019

    # Concat the dataframes
    total_cms = pd.concat([df_2016_4, df_2017_4, df_2018_4, df_2019_4], ignore_index = True)
    unique_hospital_counts = total_cms.groupby('Year')['PRVDR_NUM'].nunique()

    # Plot
    plt.figure(figsize = (10, 8))
    unique_hospital_counts.plot(kind = 'bar', color = 'skyblue', edgecolor = 'red')
    plt.title('Number of Unique Hospitals by CMS Certification Number Over Year')
    plt.xlabel('Year')
    plt.ylabel('Number of Unique Hospitals')
    plt.grid(axis = 'y', linestyle = '--', alpha = 0.7)
    plt.show()


    ```
    b.

## Identify hospital closures in POS file (15 pts) (*)

1. 
```{python}
#filter active hospital in 2016-2019
active_2016 = df_2016[df_2016['PGM_TRMNTN_CD'] == 'Active']
active_2017 = df_2017[df_2017['PGM_TRMNTN_CD'] == 'Active']
active_2018 = df_2016[df_2018['PGM_TRMNTN_CD'] == 'Active']
active_2019 = df_2019[df_2019['PGM_TRMNTN_CD'] == 'Active']
# Assuming 'Hospital_ID' is the unique identifier
active_hospitals_2016 = active_2016['Hospital_ID'].unique()  
```
2. 
3. 
    a.
    b.
    c.

## Download Census zip code shapefile (10 pt) 

1. 

    a.
    ## File types and the file information
    ### .shp (Shape File): 
    Contains the geometry of the features, such as points, lines, and polygons. It is the core spatial data file that defines the location, shape, and boundaries of geographical features.
    size: 837,544,580 bytes (837.5 MB on disk)
    ### .shx (Shape Index File): 
    An index for the .shp file, which helps in efficiently locating records. It stores the offsets of the geometries in the .shp file.
    size: 265,060 bytes (266 KB on disk)
    ### .dbf (Database File): 
    A dBASE file that contains attribute data associated with each shape. This file includes tabular information, such as names, population counts, or other relevant attributes of the geometries.
    size: 6,425,474 bytes (6.4 MB on disk)
    ### .prj (Projection File): 
    Describes the coordinate system and projection information used for the shapefile. It ensures that spatial data from different sources can align properly.
    size: 165 bytes (4 KB on disk)
    ### .xml (Metadata File): 
    Contains metadata, such as descriptive information about the data content, creation process, and purpose of the dataset.
    size: 15,639 bytes (16 KB on disk)

    b. 
     It will be useful going forward to having .shp and .dbf files larger. The .shp file contains the geometries, which can be bulky, while the .dbf stores attribute data. 
     However, .shx, .prj, and .xml files are expected to be relatively smaller since they only store index, projection, and metadata information, respectively. 
     After unzipping, the size of those files shows in a.

2. 
```{python}
import geopandas as gpd

# Load the shapefile and the cleaned POS file
shapefile_path = '/Users/yuewang1/Desktop/python 2/hw4/gz_2010_us_860_00_500k/gz_2010_us_860_00_500k.shp' 
gdf = gpd.read_file(shapefile_path)
pos_path = "cleaned_pos_2016.csv"  # 这个地方是第二问the cleaned POS file 
pos_df = pd.read_csv(pos_path)

# Filter to Texas ZIP code
gdf_zipcodes = gdf[gdf['ZCTA5CE10'].str.startswith(('75', '76', '77', '78', '79', '88'))]
pos_hospitals = pos_df[pos_df['zip_code'].str.startswith(('75', '76', '77', '78', '79', '88'))]

# Count number of hospitals per ZIP code
hospital_counts = pos_hospitals['zip_code'].value_counts().reset_index()
hospital_counts.columns = ['zip_code', 'hospital_count']
gdf_zipcodes = gdf_zipcodes.merge(hospital_counts, left_on='ZCTA5CE10', right_on='zip_code', how='left').fillna(0)

# Plot choropleth
fig, ax = plt.subplots(figsize=(12, 12))
gdf_zipcodes.plot( column='hospital_count', cmap='OrRd', linewidth=0.8, ax=ax, edgecolor='0.8', legend=True)
ax.set_title('Number of Hospitals per Zip Code in Texas (2016)')
plt.axis('off')
plt.show()

```

## Calculate zip code’s distance to the nearest hospital (20 pts) (*)

1. 
2. 
3. 
4. 
    a.
    b.
    c.
5. 
    a.
    b.
    c.
    
## Effects of closures on access in Texas (15 pts)

1. 
2. 
3. 
4. 

## Reflecting on the exercise (10 pts) 
